unet:
  n_blocks: 4
  n_layers_per_block: 8
  n_first_block_channels: 48
  _activation: "new_gelu"
  ln_eps: 1e-4
  device: "cuda"
  _dtype: "float16"
  noise_proj_init_std_factor: 1e-2

discriminator:
  n_blocks: 5
  n_layers_per_block: 4
  n_first_block_channels: 48
  _activation: "new_gelu"
  ln_eps: 1e-4
  device: "cuda"
  _dtype: "float16"
  loss_eps: 1e-5
  discriminator_cheat_loss: 1e-1
  cheat_loss_eps: 1e-3  # Lower value = stronger gradient around generator, but more unstable training.

optimizer:
  _optimizer: "adamw"
  lr: 2e-4
  weight_decay: 5e-2
  lr_schedule: "invsqrt"
  adam_eps: 1e-4
  beta1: 0.9
  beta2: 0.995
  warmup_iters: 10_000
  max_iters: 100_000
  init_std: 5e-3
  batch_size: 12

source_files_path: "/home/kanhar/workspace/gans/pytorch-deepdream/wider/images"
processed_files_path: "/home/kanhar/workspace/gans/pytorch-deepdream/data/out-images/RESNET50_IMAGENET/"
eval_interval: 200
eval_iters: 50
log_interval: 10
wandb_log: true
wandb_run_name: "high-gamma-run"
image_size: 64
discriminator_deepdream_loss_factor: 0.2
discriminator_generated_loss_factor: 0.2
discriminator_mixed_loss_factor: 0.6
generator_lr_multiplier: 1.0
discriminator_lr_multiplier: 1.0
scale_factor: 8
mixer_gamma: 2.0  # Higher = more samples near the generator, less around reference.
  # Useful for creating better gradients around the generated image.
save_interval: 5000
